res <- residuals(fc)
Acf(res)
test <- Box.test(res, lag=4, fitdf = 0, type = "Lj")
if (test["p.value"] < 0.05){
print ("Not a white noise")
} else {
print ("White noise")
}
require(fpp)
data(ausbeer)
beer <- window(ausbeer,start=1992)
res = residuals(snaive(beer))
acf(res)
require(fpp)
data(ausbeer)
fit <- window(ausbeer,start=1992)
res = residuals(snaive(fit))
acf(res)
fit <- window(ausbeer,start=1992)
fit
res = residuals(snaive(fit))
acf(res)
Acf(res)
require(fpp)
data(ausbeer)
fit <- window(ausbeer,start=1992)
res = residuals(snaive(fit))
Acf(res)
value<-Box.test(residuals(snaive(fit)), fitdf=0,type = "Lj")
if (value["p.value"] < 0.05){
print ("Not a white noise.")
} else {
print ("White noise.")
}
#-----------------------------
require (multcomp)
install.packages("multcomp")
#---------------------------
require (multcomp)
attach (cholesterol)
head (cholesterol)
table(trt)
aggregate (response, by=list(trt), FUN=mean)
aggregate (response, by=list(trt), FUN=sd)
fit <- aov (response ~ trt)
summary(fit)
# Plot group means and confidence intervals
library (gplots)
library (gplots)
install.packages("gplots")
library (gplots)
plotmeans (response ~trt, xlab="Treatment",
ylab = "Cholesterol Reduction",
main="Means with 95% CI")
# F-test is significant:
#  Conclusion: five treatments are not equally effective
# But: it does not tell which treatments differ from one another
# Use: TukeyHSD() to test all pairwise differences or
#      glht() for multiple mean comparisons
TukeyHSD(fit)
par(las=2)
par (mar=c(5,8,4,2))
plot (TukeyHSD(fit))
library(multicomp)
par (mar = c(5,4,6,2))
comp <- glht(fit, linfct=mcp(trt="Tukey"))
plot (cld(comp, level=0.05), col="lightgrey")
install.packages("multicomp")
comp <- glht(fit, linfct=mcp(trt="Tukey"))
plot (cld(comp, level=0.05), col="lightgrey")
#-----------------------------------------------
# Assumptions underlying one-way ANOVA tests:
#  Dependent var: is normally distributed
#  Dependent var: has equal variance in each trt group
#  ANOVA can be sensistive to outliers
#-----------------------------------------------
library (car)
lm.fit <- lm(response ~ trt, data=cholesterol)
qqPlot (lm.fit, simulate=TRUE,
main="Q-Q Plot", labels=FALSE)
# test equality / homegeneity of variances
bartlett.test (response ~ trt, data=cholesterol)
# test for outliers: NA is p-value > 1
# Significant test: No indication of outliers
library(car)
outlierTest(fit)
library(multcomp)
comp <- glht(fit, linfct=mcp(trt="Tukey"))
plot (cld(comp, level=0.05), col="lightgrey")
#-----------------------------------------------
# Assumptions underlying one-way ANOVA tests:
#  Dependent var: is normally distributed
#  Dependent var: has equal variance in each trt group
#  ANOVA can be sensistive to outliers
#-----------------------------------------------
library (car)
data(package="fpp")
plot(elecequip)
plot(elecequip)
library(fpp)
plot(elecequip)
ets(elecequip)
#decompose using stl
fit<-stl(elecequip,s.window = "periodic")
plot(fit,col="green",main="Electrical equipments.")
plot(fit,col="blue",main="Electrical equipments.")
plot(elecequip,col="red", main="Electrical equipments.")
lines(seasadj(fit), col="blue", main="seasonally adjusted elecequip")
seasonal_adj<-seasadj(fit)
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
result<-auto.arima(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
acf(result)
ndiff<-ndiffs(result)
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 7. Use auto.arima() on the time series data obtained after Step #6. What are the values of p, d, and q in ARIMA (p, d, q) model that the model has chosen (use summary() on the model)
result<-auto.arima(result)
result<-auto.arima(result,approximation=FALSE,trace=FALSE)
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 7. Use auto.arima() on the time series data obtained after Step #6. What are the values of p, d, and q in ARIMA (p, d, q) model that the model has chosen (use summary() on the model)
result<-auto.arima(result,approximation=FALSE,trace=FALSE)
summary(auto.arima(result))
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
# Check error/trend/seasonal of elecequip
ets(elecequip)
#decompose using stl
fit<-stl(elecequip, s.window="periodic")
plot(fit,col="blue",main="Electrical equipments.")
# 3. If the data is seasonal, create and plot the seasonally adjusted data using seasadj().
plot(elecequip,col="red", main="Electrical equipments.")
lines(seasadj(fit), col="blue", main="seasonally adjusted elecequip")
seasonal_adj<-seasadj(fit)
# 4. Apply Box-Cox transformation only if there is there is the need to stabilize the variance of the time series obtained in Step 3.
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 7. Use auto.arima() on the time series data obtained after Step #6. What are the values of p, d, and q in ARIMA (p, d, q) model that the model has chosen (use summary() on the model)
result<-auto.arima(result,approximation=FALSE,trace=FALSE)
# to remove the Warning message:
#In auto.arima(result) :
# Unable to fit final model using maximum likelihood. AIC value approximated
# used -- approximation=FALSE,trace=FALSE)
# ref http://stats.stackexchange.com/questions/89316/warning-message-in-auto-arima
summary(auto.arima(result))
summary(result)
Arima(result, order=c(4,0,0))
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 7. Use auto.arima() on the time series data obtained after Step #6. What are the values of p, d, and q in ARIMA (p, d, q) model that the model has chosen (use summary() on the model)
result<-auto.arima(result,approximation=FALSE,trace=FALSE)
# to remove the Warning message:
#In auto.arima(result) :
# Unable to fit final model using maximum likelihood. AIC value approximated
# used -- approximation=FALSE,trace=FALSE)
# ref http://stats.stackexchange.com/questions/89316/warning-message-in-auto-arima
summary(result)
# 8. Generate your own ARIMA(4, 0, 0), ARIMA (3, 0,0) and ARIMA (2, 0, 0) models using the following command:
#Arima(ts.data, order=c(4,0,0))
Arima(result, order=c(4,0,0))
Arima(result.data, order=c(4,0,0))
Arima(result, order=c(4,0,0))
result1<-auto.arima(result,approximation=FALSE,trace=FALSE)
lambda<-BoxCox.lambda(seasonal_adj)
result<-BoxCox(seasonal_adj,lambda)
# 5. Confirm if the resulting data after Step 4 is stationary.
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 6. If the data is non-stationary, then take the first difference of the data or run the unit root test to get the proper differencing order and check whether the differencing converted non-stationary ts to a stationarity one.
ndiff<-ndiffs(result)
result<- diff(result,differences=ndiff)
plot(result)
acf(result)
Box.test(result, lag=10, fitdf=0, type="Lj")
# 7. Use auto.arima() on the time series data obtained after Step #6. What are the values of p, d, and q in ARIMA (p, d, q) model that the model has chosen (use summary() on the model)
result1<-auto.arima(result,approximation=FALSE,trace=FALSE)
# to remove the Warning message:
#In auto.arima(result) :
# Unable to fit final model using maximum likelihood. AIC value approximated
# used -- approximation=FALSE,trace=FALSE)
# ref http://stats.stackexchange.com/questions/89316/warning-message-in-auto-arima
summary(result)
# 8. Generate your own ARIMA(4, 0, 0), ARIMA (3, 0,0) and ARIMA (2, 0, 0) models using the following command:
#Arima(ts.data, order=c(4,0,0))
Arima(result, order=c(4,0,0))
Arima(result, order=c(3,0,0))
Arima(result, order=c(2,0,0))
summary(result1)
acf(residuals(result))
acf(residuals(result1))
Box.test(residuals(result), lag=10, fitdf=0, type="Lj")
Box.test(residuals(result1), lag=10, fitdf=0, type="Lj")
plot(forecast(result))
plot(forecast(result1))
cat("\014")
hhelp()
require(fpp)
# load fpp package
library(fpp)
data(dj)
plot(dj)
acf(dj)
Box.test(dj, lag=10, fitdf=0, type="Lj")
temp<-dj
nd<- ndiffs(temp)
if(nd>0){
temp <- diff(temp,differences=nd)
}
plot(temp)
acf(temp)
Box.test(temp, lag=10, fitdf=0, type="Lj")
require("fma")
require("fpp")
library(package ="fpp")
library(package = "fma")
#1 usnetelec
plot(usnetelec)
#acf(usnetelec)
Box.test(usnetelec, lag=10, fitdf=0, type="Lj")
temp1<-usnetelec
#lambda<-BoxCox.lambda(temp1)
#temp1<-BoxCox(temp1,lambda)
nd<-ndiffs(temp1)
temp1 <- diff(temp1,differences=nd)
plot(temp1)
acf(temp1)
Box.test(temp1, lag=10, fitdf=0, type="Lj")
###################################################
plot(log(usgdp))
acf(usnetelec)
Box.test(usnetelec, lag=10, fitdf=0, type="Lj")
temp1<-usnetelec
#lambda<-BoxCox.lambda(temp1)
#temp1<-BoxCox(temp1,lambda)
nd<-ndiffs(temp1)
temp1 <- diff(temp1,differences=nd)
plot(temp1)
acf(temp1)
Box.test(temp1, lag=10, fitdf=0, type="Lj")
require("fma")
require("fpp")
library(package ="fpp")
library(package = "fma")
#1 usnetelec
plot(usnetelec)
acf(usnetelec)
Box.test(usnetelec, lag=10, fitdf=0, type="Lj")
#lambda<-BoxCox.lambda(usnetelec)
#temp<-BoxCox(usnetelec,lambda)
nd<-ndiffs(usnetelec)
temp <- diff(usnetelec,differences=nd)
plot(temp)
acf(temp)
Box.test(temp, lag=10, fitdf=0, type="Lj")
plot(usnetelec)
acf(usnetelec)
Box.test(usnetelec, lag=10, fitdf=0, type="Lj")
lambda<-BoxCox.lambda(usnetelec)
temp<-BoxCox(usnetelec,lambda)
nd<-ndiffs(usnetelec)
temp <- diff(usnetelec,differences=nd)
plot(temp)
acf(temp)
Box.test(temp, lag=10, fitdf=0, type="Lj")
library(igraph)
library(lsa)
graph <- read.graph(file="data/fb_caltech_small_edgelist.txt", format = c("edgelist"))
getcwd()
getwd()
setwd("/home/sud/Desktop/BI/06.Topic-7.Project-6.MarketSegmentation.AttributedGraphCommunityDetection")
graph <- read.graph(file="data/fb_caltech_small_edgelist.txt", format = c("edgelist"))
attrData <- read.csv("data/fb_caltech_small_attrlist.csv")
member <- 1:324
alpha <- 0.5
A = get.adjacency(graph, sparse = FALSE)
S = cosine(A)
print(S)
D = 1-S
# distance object
d = as.dist(D)
find_similarity <-  function(ind)
print(d)
graph <- read.graph(file="data/fb_caltech_small_edgelist.txt", format = c("edgelist"))
attrData <- read.csv("data/fb_caltech_small_attrlist.csv")
member <- 1:324
alpha <- 0.5
A = get.adjacency(graph, sparse = FALSE)
S = cosine(A)
print(S)
D = 1-S
# distance object
d = as.dist(D)
print(d)
#install.packages("lsa")
#install.packages("igraph")
#install.packages("plyr")
library(igraph)
library(lsa)
library(plyr)
graph <- read.graph(file="data/fb_caltech_small_edgelist.txt", format = c("edgelist"))
attrData <- read.csv("data/fb_caltech_small_attrlist.csv")
member <- 1:vcount(graph)
alpha <- 1.0
find_similarity <-  function(ind,mem,val)
{
temp <- which(mem==val)
len <- length(temp)
ans <- 0.0
for(n in 1:len)
{
ans <- ans + sim[ind,temp[n]]
}
return (ans/(len*len))
}
sim <- matrix(nrow = vcount(graph),ncol = vcount(graph))
for (i in 1:vcount(graph))
{
for (j in i:vcount(graph))
{
sim[i, j] = cosine(as.numeric(attrData[i,]), as.numeric(attrData[j,]))
sim[j, i]= sim[i, j]
}
}
print(sim)
for(ctr in 1:15)
{
old_member <- member
print(ctr)
for(i in 1:324)
{
QNewman_initial <- modularity(graph, membership = member)
maxval <- -2
index <- i
mem_ini <- member[i]
for(j in 1:324)
{
member[i] = member[j]
QNewman_new <- modularity(graph, membership = member)
QNewman_delta <- QNewman_new - QNewman_initial
QAttr <- find_similarity(i,member,member[j]) / length(unique(member))
gain <- (alpha*QNewman_delta) + ((1-alpha)*QAttr)
if(gain>maxval)
{
index <- j
maxval <- gain
}
}
member[i] = mem_ini
if(maxval>0)
{
member[i] = member[index]
}
}
print(identical(old_member,member))
print(member)
if(identical(old_member,member))
break
}
col<-member
colors <- rainbow(max(col))
plot(graph,vertex.color=colors[col], layout=layout.fruchterman.reingold, vertex.label= NA)
com=unique(member)
for(i in 1:length(com)){
t=which(member == com[i])
t=t-1
write(t, file = "communities.txt", sep = ",", append = TRUE, ncolumns = vcount(graph))
}
library(igraph)
#install.packages("akmeans")
library("akmeans")
## Influence Propagation
# Arguments:
# Graph = Structural Graph, Igraph Instance
# Comm  = Communiity/Clusters
# Beta = Influence Propagation Rate
influence_propagation <- function(graph, comm, beta=0.75){
output = c()
v = vcount(graph)
nodes <- data.frame(1:v)
colnames(nodes) <- c("Id")
nodes$comm = comm
nodes$color = "green"
influencers = c()
for(k in unique(comm)){
influencer = sample(nodes[which(nodes$comm %in% k), c("Id")],1)
influencers = append(influencers, influencer)
}
nodes[nodes$Id %in% influencers, c("color")] <- "red"
new_influencers = influencers
total_influencers = length(influencers)
timestep = 1
old_influencers = 0
ratio = total_influencers/v
cat("Time Step = " , timestep,", Total Influencers = ", total_influencers, ", Network Coverage = " , ratio ,"\n")
output = data.frame(timestep, total_influencers)
timestep = timestep + 1
alpha = 0.7
#while(total_influencers - old_influencers > 0 && ratio < 1){
for(i in 1:15){
old_influencers = total_influencers
influencers = new_influencers
for(i in influencers){
nbs = neighbors(graph, i)
## Selection if the propagation is inside community or outside
flag = "inside"
if(sample(1:100, 1) <= alpha*100){
candidates = nodes[nodes$comm == nodes[i, c("comm")] & nodes$color == "green", c("Id")]
candidates = intersect(candidates, nbs)
ids <- c()
for(j in candidates){
if(j %in% nbs && sample(1:100, 1) <= beta * 100){     # Stochastically determining if node will get infected, using beta transmission probability
ids <- append(ids, j)
}
}
}else{
candidates = nodes[nodes$comm != nodes[i, c("comm")] & nodes$color == "green", c("Id")]
candidates = intersect(candidates, nbs)
ids <- c()
for(j in candidates){
if(sample(1:100, 1) <= beta * 100){     # Stochastically determining if node will get infected, using beta transmission probability
ids <- append(ids, j)
}
}
}
nodes[which(nodes$Id %in% ids), c("color")] <- "red"
total_influencers = nrow(nodes[nodes$color == "red",])
new_influencers = append(new_influencers, unique(ids))
}
ratio = nrow(nodes[nodes$color == "red",])/v
cat("Time Step = " ,timestep,", Total Influencers = ", total_influencers, ", Network Coverage = ", ratio ,"\n")
output = rbind(output, data.frame(timestep, total_influencers))
timestep = timestep + 1
}
output
}
## Influence Propagation Example
# ===== Reading the graph ====== #
g <- read.graph(file="data/fb_caltech_small_edgelist.txt", format = c("edgelist"))
# ===== Read communities file ==== #
comm = integer(vcount(g))
conn <- file("communities.txt", open="r")
lines <-readLines(conn)
for (i in 1:length(lines)){
verts = unlist(strsplit(lines[i], ","))
verts = as.integer(verts) + 1   # R indexes start at 1
comm[verts] = i
}
close(conn)
# ===== Clusters From Adaptive K-means ===== #
attrData <- read.csv("data/fb_caltech_small_attrlist.csv")
akm = akmeans(attrData, d.metric=2, ths3=.4, mode=3,
min.k=length(unique(comm)), max.k=length(unique(comm))) ## cosine distance based
# ===== Influence Propagation Using adaptive k-means clusters ===== #
op1 = influence_propagation(graph=g, comm = akm$cluster)
# ===== Influence Propagation Using SAC-1 communities  ===== #
op2 = influence_propagation(graph=g, comm = comm)
print("here")
## Plot for the timestep comparison
tsteps = as.vector(op1$timestep)
tsteps = append(tsteps, as.vector(op2$timestep))
plot(op1, type="b", col=2, pch=20, ylim = c(0, vcount(g)), xlim = c(1, max(tsteps)), main = "Influence Propagation")
points(op2, type="b", col=3, pch=20)
legend("bottomright",  c("Adaptive-Kmeans","SAC-1"), col=2:3, pch=c(20,20))
